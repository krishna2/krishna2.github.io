https://nlp.seas.harvard.edu/2018/04/03/attention.html

https://bastings.github.io/annotated_encoder_decoder/


http://jalammar.github.io/illustrated-word2vec/

https://towardsdatascience.com/learn-word2vec-by-implementing-it-in-tensorflow-45641adaf2ac

https://machinelearningmastery.com/develop-word-embeddings-python-gensim/

https://towardsdatascience.com/illustrated-guide-to-recurrent-neural-networks-79e5eb8049c9

https://www.saama.com/blog/attention-mechanism-benefits-and-applications/

https://explosion.ai/blog/deep-learning-formula-nlp

https://ruder.io/deep-learning-nlp-best-practices/index.html#attention

https://towardsdatascience.com/attn-illustrated-attention-5ec4ad276ee3


https://www.searchenginejournal.com/bert-generate-meta-descriptions/332585/amp/


https://towardsdatascience.com/nlp-extract-contextualized-word-embeddings-from-bert-keras-tf-67ef29f60a7b

https://blog.scaleway.com/2019/understanding-text-with-bert/amp/


https://towardsdatascience.com/understanding-bert-is-it-a-game-changer-in-nlp-7cca943cf3ad

https://israelg99.github.io/2017-03-23-Word2Vec-Explained/

https://www.wired.com/story/ai-pioneer-algorithms-understand-why/amp


https://towardsdatascience.com/deconstructing-bert-reveals-clues-to-its-state-of-art-performance-in-nlp-tasks-76a7e828c0f1


https://towardsdatascience.com/nlp-extract-contextualized-word-embeddings-from-bert-keras-tf-67ef29f60a7b

https://towardsdatascience.com/bert-classifier-just-another-pytorch-model-881b3cf05784


https://github.com/bollu/bollu.github.io#everything-you-know-about-word2vec-is-wrong


https://medium.com/apache-mxnet/gluon-nlp-bert-6a489bdd3340

http://jalammar.github.io/illustrated-transformer/



http://nlp.fast.ai/classification/2018/05/15/introducting-ulmfit.html

https://towardsdatascience.com/document-embedding-techniques-fed3e7a6a25d

https://blog.scaleway.com/2019/building-a-machine-reading-comprehension-system-using-the-latest-advances-in-deep-learning-for-nlp/



https://blog.floydhub.com/gpt2/

https://transformer.huggingface.co/

https://towardsdatascience.com/an-implementation-guide-to-word2vec-using-numpy-and-google-sheets-13445eebd281


http://ruder.io/state-of-transfer-learning-in-nlp/

http://www.peterbloem.nl/blog/transformers

http://nlp.seas.harvard.edu/2018/04/03/attention.html


https://towardsdatascience.com/animated-rnn-lstm-and-gru-ef124d06cf45

https://towardsdatascience.com/attn-illustrated-attention-5ec4ad276ee3

https://towardsdatascience.com/illustrated-efficient-neural-architecture-search-5f7387f9fb6

https://towardsdatascience.com/an-implementation-guide-to-word2vec-using-numpy-and-google-sheets-13445eebd281


https://jalammar.github.io/illustrated-word2vec/

https://www.preview.nearist.ai/paid-ebook-and-tutorial

http://ruder.io/word-embeddings-1/index.html

http://ruder.io/word-embeddings-softmax/

https://web.stanford.edu/~jurafsky/slp3/


https://jalammar.github.io/illustrated-bert/


https://towardsdatascience.com/neural-networks-and-philosophy-of-language-31c34c0796da

https://allennlp.org/elmo

https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html








