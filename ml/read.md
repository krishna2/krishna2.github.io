Gmail	Krishna Srinivasan <krishna2@gmail.com>
Entire NLP/ML/DL literature (Was: Advanced NLP Course to do on Coursera)
1 message
Krishna Srinivasan <krishna2@gmail.com>	Sat, Jan 11, 2020 at 8:39 AM
To: Krishna Srinivasan <krishna2@gmail.com>
This is the entire email thread of the original subject ("Advanced NLP Course to do on Coursera"). This email has the replies unindented - so it is easy to read in "print" view - as a page of all links. Next step is to edit this and order them in the right order to read.

---------- Forwarded message ---------
From: Krishna Srinivasan <krishna2@gmail.com>
Date: Fri, Dec 6, 2019 at 5:42 PM
Subject: Re: Advanced NLP Course to do on Coursera
To: Krishna Srinivasan <krishna2@gmail.com>


GitHub - trekhleb/nano-neuron: NanoNeuron is 7 simple JavaScript functions that will give you a feeling of how machines can actually "learn"
https://github.com/trekhleb/nano-neuron

Show HN: AI Dungeon 2 – AI-generated text adventure built with 1.5B param GPT-2 | Hacker News
https://news.ycombinator.com/item?id=21717022

The unending quest to explain consciousness | Hacker News
https://news.ycombinator.com/item?id=21706591

Making a text adventure game with GPT2 | Hacker News
https://news.ycombinator.com/item?id=21711808

1911.05289.pdf
https://arxiv.org/pdf/1911.05289.pdf

1701.06538.pdf
https://arxiv.org/pdf/1701.06538.pdf

How to apply machine learning and deep learning methods to audio analysis
https://medium.com/comet-ml/applyingmachinelearningtoaudioanalysis-utm-source-kdnuggets11-19-e160b069e88

Neural Networks, Types, and Functional Programming -- colah's blog
https://colah.github.io/posts/2015-09-NN-Types-FP/

[1911.08265] Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model
https://arxiv.org/abs/1911.08265

BERT Explained: A Complete Guide with Theory and Tutorial – Towards Machine Learning
https://towardsml.com/2019/09/17/bert-explained-a-complete-guide-with-theory-and-tutorial/

[1910.10683] Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer
https://arxiv.org/abs/1910.10683

[1911.11423] Single Headed Attention RNN: Stop Thinking With Your Head
https://arxiv.org/abs/1911.11423

1910.11664.pdf
https://arxiv.org/pdf/1910.11664.pdf



On Tue, Dec 3, 2019 at 3:27 PM Krishna Srinivasan <krishna2@gmail.com> wrote:
https://www.tradientblog.com/2019/11/lessons-learned-building-an-ml-trading-system-that-turned-5k-into-200k/
https://news.ycombinator.com/item?id=21647038

https://www.amazon.com/Advances-Financial-Machine-Learning-Marcos-ebook-dp-B079KLDW21/dp/B079KLDW21/ref=mt_kindle?_encoding=UTF8&me=&qid=
https://arxiv.org/list/q-fin/recent

https://arxiv.org/abs/1911.12540


https://www.amazon.com/Python-Finance-Mastering-Data-Driven-ebook/dp/B07L8NMW2P/ref=pd_sim_351_1/146-4144694-8829567?_encoding=UTF8&pd_rd_i=B07L8NMW2P&pd_rd_r=c06af488-9699-4a09-8052-fbfe21eabfce&pd_rd_w=BMT8T&pd_rd_wg=WxTNm&pf_rd_p=04d27813-a1f2-4e7b-a32b-b5ab374ce3f9&pf_rd_r=1V2BQF6YFMJNTDGMZCDB&psc=1&refRID=1V2BQF6YFMJNTDGMZCDB



On Tue, Dec 3, 2019 at 1:46 PM Krishna Srinivasan <krishna2@gmail.com> wrote:
Terence Parr : Matrics Calculus for DL:
https://explained.ai/matrix-calculus/index.html
https://explained.ai/

https://www.ethanhein.com/wp/2016/visualizing-hip-hop-melodies/

Calculus explained with GIFs:https://news.ycombinator.com/item?id=21671112


Trouble in ML:
https://arxiv.org/abs/1807.03341

Hofstader on Google Translate:https://www.theatlantic.com/technology/archive/2018/01/the-shallowness-of-google-translate/551570/




On Sun, Dec 1, 2019 at 7:41 PM Krishna Srinivasan <krishna2@gmail.com> wrote:
Calculus: https://0a.io/chapter1/calculus-explained.htmlJim Fowler Calculus: https://www.youtube.com/channel/UCt1n_c_lbPIvz_ycw3Eq96w



On Fri, Nov 22, 2019 at 9:09 AM Krishna Srinivasan <krishna2@gmail.com> wrote:
Copy of BERT_lab.ipynb - Colaboratory
https://colab.research.google.com/drive/1-UdelAqtD_2KrUIV_NTL59kgqo8m1Y2H#scrollTo=lJLcUBF5GOyU
------

Attention, CNN and what not for Text Classification
https://towardsdatascience.com/nlp-learning-series-part-3-attention-cnn-and-what-not-for-text-classification-4313930ed566
------

TextCNN - Pytorch and Keras | Kaggle
https://www.kaggle.com/mlwhiz/textcnn-pytorch-and-keras
------

cmasch/cnn-text-classification: Text classification with Convolution Neural Networks on Yelp, IMDB & sentence polarity dataset v1.0
https://github.com/cmasch/cnn-text-classification
------

Ronan Collobert - Google Scholar Citations
https://scholar.google.com/citations?user=32w7x1cAAAAJ&hl=en
------

The Annotated Transformer
https://nlp.seas.harvard.edu/2018/04/03/attention.html
------

The Annotated Encoder Decoder | A PyTorch tutorial implementing Bahdanau et al. (2015)
https://bastings.github.io/annotated_encoder_decoder/
------

Receiver operating characteristic - Wikipedia
https://en.wikipedia.org/wiki/Receiver_operating_characteristic
------

Understanding AUC - ROC Curve - Towards Data Science
https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5
------

Understanding Confusion Matrix - Towards Data Science
https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62
------

The Illustrated Word2vec – Jay Alammar – Visualizing machine learning one concept at a time
http://jalammar.github.io/illustrated-word2vec/
------

Learn Word2Vec by implementing it in tensorflow - Towards Data Science
https://towardsdatascience.com/learn-word2vec-by-implementing-it-in-tensorflow-45641adaf2ac
------

How to Develop Word Embeddings in Python with Gensim
https://machinelearningmastery.com/develop-word-embeddings-python-gensim/
------

Deep Learning For Natural Language Processing
https://machinelearningmastery.com/deep-learning-for-nlp/
------

Text Generation With LSTM Recurrent Neural Networks in Python with Keras
https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/
------

Magenta
https://magenta.tensorflow.org/
------

Generating Piano Music with Transformer
https://magenta.tensorflow.org/piano-transformer
------

Magenta Studio
https://magenta.tensorflow.org/studio
------

Google Magenta-Making Music with MIDI and Machine Learning -
https://www.midi.org/articles-old/google-magenta-making-music-with-midi-and-machine-learning
------

Behind Magenta, the tech that rocked I/O
https://blog.google/technology/ai/behind-magenta-tech-rocked-io/
------

Simple Introduction to Convolutional Neural Networks
https://towardsdatascience.com/simple-introduction-to-convolutional-neural-networks-cdf8d3077bac
------

Illustrated: 10 CNN Architectures - Towards Data Science
https://towardsdatascience.com/illustrated-10-cnn-architectures-95d78ace614d
------

An intuitive guide to Convolutional Neural Networks
https://www.freecodecamp.org/news/an-intuitive-guide-to-convolutional-neural-networks-260c2de0a050/
------

The best explanation of Convolutional Neural Networks on the Internet!
https://medium.com/technologymadeeasy/the-best-explanation-of-convolutional-neural-networks-on-the-internet-fbb8b1ad5df8
------

An Intuitive Explanation of Convolutional Neural Networks – the data science blog
https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/
------

Illustrated Guide to Recurrent Neural Networks - Towards Data Science
https://towardsdatascience.com/illustrated-guide-to-recurrent-neural-networks-79e5eb8049c9
------

Illustrated Guide to Recurrent Neural Networks
http://kurious.pub/blog/4
------

The Basics Of Recurrent Neural Networks (RNN) | Built In
https://builtin.com/data-science/recurrent-neural-networks-and-lstm
------

The Beginner’s Guide to Recurrent Neural Networks and Text Generation
https://medium.com/@annikabrundyn1/the-beginners-guide-to-recurrent-neural-networks-and-text-generation-44a70c34067f
------

A Beginner's Guide to LSTMs and Recurrent Neural Networks | Skymind
https://skymind.ai/wiki/lstm
------

karpathy/char-rnn: Multi-layer Recurrent Neural Networks (LSTM, GRU, RNN) for character-level language models in Torch
https://github.com/karpathy/char-rnn
------

A Brief History of Word Embeddings | Gavagai
https://www.gavagai.io/text-analytics/a-brief-history-of-word-embeddings/
------

On word embeddings - Part 1
https://ruder.io/word-embeddings-1/index.html
------

Approximating the Softmax for Learning Word Embeddings
https://ruder.io/word-embeddings-softmax/
------

On word embeddings - Part 3: The secret ingredients of word2vec
https://ruder.io/secret-word2vec/index.html
------

A survey of cross-lingual word embedding models
https://ruder.io/cross-lingual-embeddings/index.html
------

Word embeddings in 2017: Trends and future directions
https://ruder.io/word-embeddings-2017/index.html
------

Neural networks [10.7] : Natural language processing - hierarchical output layer - YouTube
https://www.youtube.com/watch?v=B95LTf2rVWM
------

Neural networks [1.1] : Feedforward neural network - artificial neuron - YouTube
https://www.youtube.com/watch?v=SGZ6BttHMPw&list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH
------

Sebastian Ruder
https://ruder.io/
------

Thread by @seb_ruder: "David Silver on Principles for Reinforcement Learning at the . Important principles that are not only applicable to RL, but to […]" #DLIndaba2018
https://threadreaderapp.com/thread/1040235236284669952.html
------

10 Exciting Ideas of 2018 in NLP
https://ruder.io/10-exciting-ideas-of-2018-in-nlp/
------

HackerNoon Interview
https://ruder.io/hackernoon-interview/
------

Requests for Research
https://ruder.io/requests-for-research/
------

1909.04547.pdf
https://arxiv.org/pdf/1909.04547.pdf
------

David Silver (computer scientist) - Wikipedia
https://en.wikipedia.org/wiki/David_Silver_(computer_scientist)
------

David Silver - Google Scholar Citations
https://scholar.google.com/citations?user=-8DNE4UAAAAJ&hl=en
------

neural networks non linearity - Google Search
https://www.google.com/search?q=neural+networks+non+linearity&oq=neural+networks+non-lin&aqs=chrome.2.69i57j0l5.7420j0j1&sourceid=chrome&ie=UTF-8
------

Neural networks and deep learning
http://neuralnetworksanddeeplearning.com/chap4.html
------

A Neural Network Playground
http://playground.tensorflow.org/#activation=linear&batchSize=20&dataset=circle&regDataset=reg-gauss&learningRate=0.003&regularizationRate=0.001&noise=0&networkShape=4,2&seed=0.87118&showTestData=false&discretize=true&percTrainData=80&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=regression&initZero=false&hideText=false
------

A Neural Network Playground
http://playground.tensorflow.org/#activation=relu&batchSize=20&dataset=circle&regDataset=reg-gauss&learningRate=0.003&regularizationRate=0.001&noise=0&networkShape=4,2&seed=0.97957&showTestData=false&discretize=true&percTrainData=80&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=regression&initZero=false&hideText=false
------

Visualizing The Non-linearity of Neural Networks - Towards Data Science
https://towardsdatascience.com/visualizing-the-non-linearity-of-neural-networks-c55b2a14ad7a
------

Why do you need non-linear activation functions? - Shallow neural networks | Coursera
https://www.coursera.org/lecture/neural-networks-deep-learning/why-do-you-need-non-linear-activation-functions-OASKH
------

what makes neural networks a nonlinear classification model? - Cross Validated
https://stats.stackexchange.com/questions/222639/what-makes-neural-networks-a-nonlinear-classification-model/222642
------

1905.12337.pdf
https://arxiv.org/pdf/1905.12337.pdf
------

How neural networks learn nonlinear functions and classify linearly non-separable data?
https://medium.com/@vivek.yadav/how-neural-networks-learn-nonlinear-functions-and-classify-linearly-non-separable-data-22328e7e5be1
------

CS231n Convolutional Neural Networks for Visual Recognition
http://cs231n.github.io/neural-networks-1/
------

The Illustrated Word2vec – Jay Alammar – Visualizing machine learning one concept at a time
http://jalammar.github.io/illustrated-word2vec/
------

A Visual and Interactive Guide to the Basics of Neural Networks – Jay Alammar – Visualizing machine learning one concept at a time
http://jalammar.github.io/visual-interactive-guide-basics-neural-networks/
------

A Visual And Interactive Look at Basic Neural Network Math – Jay Alammar – Visualizing machine learning one concept at a time
http://jalammar.github.io/feedforward-neural-networks-visual-interactive/
------

CS231n Convolutional Neural Networks for Visual Recognition
https://cs231n.github.io/neural-networks-1/
------

Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention) – Jay Alammar – Visualizing machine learning one concept at a time
http://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/
------

A friendly introduction to Recurrent Neural Networks - YouTube
https://www.youtube.com/watch?v=UNmqTiOnRfg
------

The Illustrated Transformer – Jay Alammar – Visualizing machine learning one concept at a time
http://jalammar.github.io/illustrated-transformer/
------

tensorflow/tensor2tensor: Library of deep learning models and datasets designed to make deep learning more accessible and accelerate ML research.
https://github.com/tensorflow/tensor2tensor
------

The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning) – Jay Alammar – Visualizing machine learning one concept at a time
http://jalammar.github.io/illustrated-bert/
------

The Illustrated GPT-2 (Visualizing Transformer Language Models) – Jay Alammar – Visualizing machine learning one concept at a time
http://jalammar.github.io/illustrated-gpt2/
------

Deep Learning, NLP, and Representations - colah's blog
http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/
------

Neural Networks, Types, and Functional Programming -- colah's blog
http://colah.github.io/posts/2015-09-NN-Types-FP/
------

Understanding LSTM Networks -- colah's blog
http://colah.github.io/posts/2015-08-Understanding-LSTMs/
------

The Unreasonable Effectiveness of Recurrent Neural Networks
http://karpathy.github.io/2015/05/21/rnn-effectiveness/
------

Andrej Karpathy Academic Website
https://cs.stanford.edu/people/karpathy/
------

Hacker's guide to Neural Networks
http://karpathy.github.io/neuralnets/
------

Attention and Augmented Recurrent Neural Networks
https://distill.pub/2016/augmented-rnns/
------

Conv Nets: A Modular Perspective - colah's blog
http://colah.github.io/posts/2014-07-Conv-Nets-Modular/
------

Understanding Convolutions - colah's blog
http://colah.github.io/posts/2014-07-Understanding-Convolutions/
------

Groups & Group Convolutions - colah's blog
http://colah.github.io/posts/2014-12-Groups-Convolution/
------

Deconvolution and Checkerboard Artifacts
https://distill.pub/2016/deconv-checkerboard/
------

Visualizing MNIST: An Exploration of Dimensionality Reduction - colah's blog
http://colah.github.io/posts/2014-10-Visualizing-MNIST/
------

Visualizing Representations: Deep Learning and Human Beings - colah's blog
http://colah.github.io/posts/2015-01-Visualizing-Representations/
------

Google AI Blog: Open Sourcing BERT: State-of-the-Art Pre-training for Natural Language Processing
https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html
------

Google AI Blog: Inceptionism: Going Deeper into Neural Networks
https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html
------

Google AI Blog: Highlights from the 3rd Cohort of the Google AI Residency Program
https://ai.googleblog.com/2019/11/highlights-from-2019-google-ai.html
------

Fast Markov chains in ~20 lines of sh, grep, cut and Awk | Hacker News
https://news.ycombinator.com/item?id=21493761
------

Naïve Bayes for Machine Learning – From Zero to Hero | Hacker News
https://news.ycombinator.com/item?id=21537314
------

NLP's ImageNet moment has arrived
https://thegradient.pub/nlp-imagenet/
------

Deep Learning for Time Series Forecasting
https://machinelearningmastery.com/deep-learning-for-time-series-forecasting/
------

tensorflow/nmt: TensorFlow Neural Machine Translation Tutorial
https://github.com/tensorflow/nmt
------



On Sun, Nov 17, 2019 at 10:10 AM Krishna Srinivasan <krishna2@gmail.com> wrote:
Very good text generation example: (in keras. trains with Nietzsche's text):https://keras.io/examples/lstm_text_generation/

DeepLizard : seems to have a full playlist of three ml/dl courses. Here are the top 4 that is of interest.
Machine Learning & Deep Learning Fundamentals
https://deeplizard.com/learn/playlist/PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU

Keras - Python Deep Learning Neural Network API
https://deeplizard.com/learn/playlist/PLZbbT5o_s2xrwRnXk_yCPtnqqo4_u2YGL

Neural Network Programming - Deep Learning with PyTorch
https://deeplizard.com/learn/playlist/PLZbbT5o_s2xrfNyHZsM6ufI0iZENK9xgG

Reinforcement Learning - Introducing Goal Oriented Intelligence
https://deeplizard.com/learn/playlist/PLZbbT5o_s2xoWNVdDudn51XM8lOuZ_Njv


On Sun, Nov 17, 2019 at 8:04 AM Krishna Srinivasan <krishna2@gmail.com> wrote:
Amazing visualization and analysis of every Nature paper published and their connections.
https://www.youtube.com/watch?v=GW4s58u8PZo&feature=youtu.be

https://www.nature.com/immersive/d41586-019-03165-4/index.html
https://www.nature.com/immersive/d41586-019-03165-4/reftree-home.html

Wonder if such a history exists for ML, NLP, esp. Music/ML.

On Sun, Nov 17, 2019 at 7:49 AM Krishna Srinivasan <krishna2@gmail.com> wrote:
MaxtonChangeJulv1.pdf
http://www.graememaxton.com/admin/resources/MaxtonChangeJulv1.pdf
------

Home - Keras Documentation
https://keras.io/#getting-started-30-seconds-to-keras
------

keras/examples at master · keras-team/keras
https://github.com/keras-team/keras/tree/master/examples
------

keras/lstm_text_generation.py at master · keras-team/keras
https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py
------

Deep Learning, NLP, and Representations - colah's blog
http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/
------

Understanding LSTM Networks -- colah's blog
http://colah.github.io/posts/2015-08-Understanding-LSTMs/
------

[1506.02078] Visualizing and Understanding Recurrent Networks
https://arxiv.org/abs/1506.02078
------

Exploring the Limits of Language Modeling
https://arxiv.org/pdf/1602.02410.pdf
------

Text Understanding from Scratch
https://arxiv.org/pdf/1502.01710v5.pdf
------

Neural Network Architectures - Towards Data Science
https://towardsdatascience.com/neural-network-architectures-156e5bad51ba
------

[1606.04474] Learning to learn by gradient descent by gradient descent
https://arxiv.org/abs/1606.04474
------

Neuroevolution of augmenting topologies - Wikipedia
https://en.wikipedia.org/wiki/Neuroevolution_of_augmenting_topologies
------

404 Not Found
http://people.idsia.ch/~daan/papers/gomez-ijcai05.pdf
------

NeuroEvolution of Augmenting Topologies
http://www.cs.ucf.edu/~kstanley/neat.html
------

Evolving Deep Neural Networks
https://arxiv.org/pdf/1703.00548.pdf
------

[1703.01041] Large-Scale Evolution of Image Classifiers
https://arxiv.org/abs/1703.01041
------

1606.02580.pdf
https://arxiv.org/pdf/1606.02580.pdf
------


On Sat, Nov 16, 2019 at 6:28 PM Krishna Srinivasan <krishna2@gmail.com> wrote:
Amazing site: NLP Explorer : http://104.154.102.7/(sadly yes, it doesn't have a web site name.. :) ).
http://104.154.102.7/papers_all


And it is itself described in a paper: https://arxiv.org/abs/1910.07351


On Sat, Nov 16, 2019 at 5:11 PM Krishna Srinivasan <krishna2@gmail.com> wrote:

https://medium.com/@rafayak/nothing-but-numpy-understanding-creating-binary-classification-neural-networks-with-e746423c8d5c
https://adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/
https://towardsdatascience.com/understanding-convolutional-neural-networks-221930904a8e
https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/
https://towardsdatascience.com/nlp-extract-contextualized-word-embeddings-from-bert-keras-tf-67ef29f60a7b

https://medium.com/swlh/transfer-learning-in-nlp-f5035cc3f62f
https://towardsdatascience.com/a-guide-to-convolutional-neural-networks-from-scratch-f1e3bfc3e2de
https://searchengineland.com/a-deep-dive-into-bert-how-bert-launched-a-rocket-into-natural-language-understanding-324522/amp

https://bytes.grubhub.com/search-query-embeddings-using-query2vec-f5931df27d79?gi=808bf4e3e025

https://arxiv.org/pdf/1911.01547.pdf
Francois Chollet's on "Need for an actionable definition and measure of intelligence".
------------------
MaxtonChangeJulv1.pdf
http://www.graememaxton.com/admin/resources/MaxtonChangeJulv1.pdf
------

Jim Simons, the Numbers King | The New Yorker
https://www.newyorker.com/magazine/2017/12/18/jim-simons-the-numbers-king
------

Slack | * assignment5 | xcs224n-scpd
https://app.slack.com/client/TMK04KFGX/CMSF6BG59
------

Difference between view, reshape, transpose and permute in PyTorch - jdhao's blog
https://jdhao.github.io/2019/07/10/pytorch_view_reshape_transpose_permute/
------

neural network - PyTorch - contiguous() - Stack Overflow
https://stackoverflow.com/questions/48915810/pytorch-contiguous
------

1901.07291.pdf
https://arxiv.org/pdf/1901.07291.pdf#page9
------

1911.02116.pdf
https://arxiv.org/pdf/1911.02116.pdf
------

Character-Aware Neural Language Models
https://arxiv.org/pdf/1508.06615.pdf
------

Highway Networks
https://arxiv.org/pdf/1505.00387.pdf
------

PyTorch: Custom nn Modules — PyTorch Tutorials 1.3.0 documentation
https://pytorch.org/tutorials/beginner/examples_nn/two_layer_net_module.html
------

Deep Learning with PyTorch: A 60 Minute Blitz — PyTorch Tutorials 1.3.0 documentation
https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html
------

NLP From Scratch: Translation with a Sequence to Sequence Network and Attention — PyTorch Tutorials 1.3.0 documentation
https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html
------

Learning PyTorch with Examples — PyTorch Tutorials 1.3.0 documentation
https://pytorch.org/tutorials/beginner/pytorch_with_examples.html
------

Language Translation with TorchText — PyTorch Tutorials 1.3.0 documentation
https://pytorch.org/tutorials/beginner/torchtext_translation_tutorial.html
------

torchaudio Tutorial — PyTorch Tutorials 1.3.0 documentation
https://pytorch.org/tutorials/beginner/audio_preprocessing_tutorial.html
------

allennlp/cnn_encoder.py at master · allenai/allennlp
https://github.com/allenai/allennlp/blob/master/allennlp/modules/seq2vec_encoders/cnn_encoder.py
------

bamtercelboo/pytorch_Highway_Networks: Highway Networks implement in pytorch
https://github.com/bamtercelboo/pytorch_Highway_Networks
------

Implementing a CNN for Text Classification in TensorFlow – WildML
http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/
------

Your First Deep Learning Project in Python with Keras Step-By-Step
https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/
------

Deep Learning with Python
http://faculty.neu.edu.cn/yury/AAI/Textbook/Deep%20Learning%20with%20Python.pdf
------

Convolutional Neural Networks (CNN) - Deep Learning Wizard
https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_convolutional_neuralnetwork/
------



On Thu, Nov 14, 2019 at 5:15 AM Krishna Srinivasan <krishna2@gmail.com> wrote:
Chris McCormick tutorials / links:
About · Chris McCormick
https://mccormickml.com/about/
------

Chris McCormick ML
https://www.chrismccormick.ai/offers/GFUU2mEb/checkout
------

BERT Word Embeddings Tutorial · Chris McCormick
https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/
------

BERT Fine-Tuning Tutorial with PyTorch · Chris McCormick
https://mccormickml.com/2019/07/22/BERT-fine-tuning/
------

Tutorials · Chris McCormick
https://mccormickml.com/tutorials/
------

Word2Vec Tutorial - The Skip-Gram Model · Chris McCormick
http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/
------

Word2Vec Tutorial Part 2 - Negative Sampling · Chris McCormick
http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/
------

Word2Vec Resources · Chris McCormick
http://mccormickml.com/2016/04/27/word2vec-resources/
------

Advanced NLP Course to do on Coursera - krishna2@gmail.com - Gmail
https://mail.google.com/mail/u/0/#inbox/QgrcJHsbjCmCVqsXCdwGkpKZvNSGPxXkNkv
------


On Thu, Nov 14, 2019 at 5:04 AM Krishna Srinivasan <krishna2@gmail.com> wrote:
Fantastic talk (transcript) by Jay Allamar on Word2Vec and Embeddings. The talk mentions recommendations embedding at Airbnb, Alibaba, Asos, Spotify etc.Here are some links to read:
Intuition & Use-Cases of Embeddings in NLP & beyond
https://www.infoq.com/presentations/nlp-word-embedding/
------

Listing Embeddings in Search Ranking - Airbnb Engineering & Data Science - Medium
https://medium.com/airbnb-engineering/listing-embeddings-for-similar-listing-recommendations-and-real-time-personalization-in-search-601172f7603e
------

Real-time Personalization using Embeddings for Search Ranking at Airbnb
https://astro.temple.edu/~tua95067/kdd2018.pdf
------

Applying word2vec to Recommenders and Advertising · Chris McCormick
https://mccormickml.com/2018/06/15/applying-word2vec-to-recommenders-and-advertising/
------

Collaborative Embeddings for Lipstick Recommendations
https://towardsdatascience.com/collaborative-embeddings-for-lipstick-recommendations-98eccfa816bd
------

Applying Deep Learning To Airbnb Search
https://arxiv.org/pdf/1810.09591.pdf
------

Real-time Personalization using Embeddings for Search Ranking at Airbnb - Semantic Scholar
https://www.semanticscholar.org/paper/Real-time-Personalization-using-Embeddings-for-at-Grbovic-Cheng/2553596e3b24444d309ae461da50370d58f1b807
------

[1803.02349] Billion-scale Commodity Embedding for E-commerce Recommendation in Alibaba
https://arxiv.org/abs/1803.02349
------

[1905.06874] Behavior Sequence Transformer for E-commerce Recommendation in Alibaba
https://arxiv.org/abs/1905.06874
------

Order Matters: Alibaba’s Transformer-based Recommender System
https://www.kdnuggets.com/2019/08/order-matters-alibabas-transformer-based-recommender-system.html
------

Finding the Right Clique: Alibaba Advances Exact-K Recommendation
https://medium.com/@alitech_2017/finding-the-right-clique-alibaba-advances-exact-k-recommendation-a3e88d23c297
------

Customer Lifetime Value Prediction Using Embeddings
http://arxiv-export-lb.library.cornell.edu/pdf/1703.02596
------

Customer Lifetime Value Prediction Using Embeddings
https://medium.com/syncedreview/customer-lifetime-value-prediction-using-embeddings-53f54e2ac59d
------

Fashion Forward – using deep learning at ASOS to predict customer lifetime value in online fashion retail – Technology and Operations Management
https://digital.hbs.edu/platform-rctom/submission/fashion-forward-using-deep-learning-at-asos-to-predict-customer-lifetime-value-in-online-fashion-retail/
------

How do ASOS use deep learning to optimise performance?
http://blog.re-work.co/how-do-asos-use-deep-learning-to-optimise-performance/
------

Table 2 from Customer Life Time Value Prediction Using Embeddings - Semantic Scholar
https://www.semanticscholar.org/paper/Customer-Life-Time-Value-Prediction-Using-Chamberlain-Cardoso/ebb7913b5c5bf1ce3b8aef8d0a4d2f0a704ba7a2/figure/3
------

Case Study: Music Recommendations at Spotify - MLRecipies - Medium
https://medium.com/mlrecipies/case-study-music-recommendations-at-spotify-3daf9d9f58c6
------

Recommending music on Spotify with deep learning – Sander Dieleman
http://benanne.github.io/2014/08/05/spotify-cnns.html
------

Building Music Playlists Recommendation System - Towards Data Science
https://towardsdatascience.com/building-music-playlists-recommendation-system-564a3e63ef64
------

How to discover new music on Spotify with Artificial Intelligence
https://towardsdatascience.com/how-to-discover-new-music-on-spotify-with-artificial-intelligence-b2110af6a611
------

Advanced NLP Course to do on Coursera - krishna2@gmail.com - Gmail
https://mail.google.com/mail/u/0/#inbox/QgrcJHsbjCmCVqsXCdwGkpKZvNSGPxXkNkv
------



On Wed, Nov 13, 2019 at 5:57 PM Krishna Srinivasan <krishna2@gmail.com> wrote:
Drawing tools on web but makes it look like hand-drawn:https://sketchviz.com/graphviz-examples
https://github.com/jgraph/drawio

Weights and Biases : wandb.com : This is by Lukas Biewalk (figure eight company): The articles and tutorials seem to cover very important material - worth a look:https://www.wandb.com/articles
https://www.wandb.com/tutorials

https://www.blog.google/technology/ai/teachable-machine/
https://michelenasti.com/2019/10/21/how-internet-ads-work.html




On Tue, Nov 12, 2019 at 4:24 PM Krishna Srinivasan <krishna2@gmail.com> wrote:
The magic of generating new ideas | Hacker News
https://news.ycombinator.com/item?id=21513790

Social Media Is Warping Democracy - The Atlantic
https://www.theatlantic.com/magazine/archive/2019/12/social-media-democracy/600763/

Open vs Closed pipes (Flutes vs Clarinets)
http://newt.phys.unsw.edu.au/jw/flutes.v.clarinets.html

GPT-2 Neural Network Poetry - Gwern.net
https://www.gwern.net/GPT-2

Optima Optometry | Optometrist | Eye Doctor | Eye Care | Eyeglasses | Contact Lenses | Santa Clara CA
https://www.optimaoptometry.com/

Attention and Augmented Recurrent Neural Networks
https://distill.pub/2016/augmented-rnns/

Michael Nielsen
http://michaelnielsen.org/

Fernanda Viégas
http://www.fernandaviegas.com/

Visualizing memorization in RNNs
https://distill.pub/2019/memorization-in-rnns/

Learning to Predict Without Looking Ahead: World Models Without Forward Prediction
https://learningtopredict.github.io/

Understanding Convolutions - colah's blog
http://colah.github.io/posts/2014-07-Understanding-Convolutions/
imagenet.pdf
http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf

https://towardsdatascience.com/demystifying-convolutional-neural-networks-384785791596
https://futurism.com/redditor-claims-love-ai-gpt-2/amp
https://thegradient.pub/nlps-clever-hans-moment-has-arrived/




On Mon, Nov 11, 2019 at 8:44 PM Krishna Srinivasan <krishna2@gmail.com> wrote:
https://news.ycombinator.com/item?id=21493761
https://machinelearningmastery.com/deep-learning-for-time-series-forecasting/
https://www.newyorker.com/magazine/2017/12/18/jim-simons-the-numbers-king

http://www.incompleteideas.net/IncIdeas/BitterLesson.html
https://rodneybrooks.com/a-better-lesson/
https://www.reddit.com/r/MachineLearning/comments/ds1xvc/d_deep_learning_has_a_size_problem_we_need_to/f6nnq8d/

https://ai.googleblog.com/2019/11/highlights-from-2019-google-ai.html

Enrolled in all these classes today in audit mode:https://www.coursera.org/specializations/tensorflow-in-practice
https://www.coursera.org/learn/introduction-tensorflow/home/welcome
https://www.coursera.org/learn/convolutional-neural-networks-tensorflow/home/welcome
https://www.coursera.org/learn/natural-language-processing-tensorflow/home/welcome
https://www.coursera.org/learn/tensorflow-sequences-time-series-and-prediction/home/welcome
https://www.coursera.org/learn/language-processing
https://www.coursera.org/learn/fundamentals-of-reinforcement-learning/home/welcome
https://www.coursera.org/learn/guided-tour-machine-learning-finance/home/welcome
https://www.coursera.org/learn/fundamentals-machine-learning-in-finance/home/welcome
https://www.coursera.org/learn/reinforcement-learning-in-finance/home/welcome
https://www.coursera.org/learn/advanced-methods-reinforcement-learning-finance/home/welcome




On Mon, Nov 11, 2019 at 8:08 PM Krishna Srinivasan <krishna2@gmail.com> wrote:
CNN, RNN, LSTM, Word2Vec, Transformer : Tutorials, intuitive explanations.
https://stackoverflow.com/questions/57048120/pytorch-lstm-vs-lstmcell
https://stackoverflow.com/questions/48187283/whats-the-difference-between-lstm-and-lstmcell
https://colab.research.google.com/drive/1-UdelAqtD_2KrUIV_NTL59kgqo8m1Y2H#scrollTo=lJLcUBF5GOyU
https://towardsdatascience.com/nlp-learning-series-part-3-attention-cnn-and-what-not-for-text-classification-4313930ed566
https://www.kaggle.com/mlwhiz/textcnn-pytorch-and-keras
https://github.com/cmasch/cnn-text-classification
https://scholar.google.com/citations?user=32w7x1cAAAAJ&hl=en
https://nlp.seas.harvard.edu/2018/04/03/attention.html
https://bastings.github.io/annotated_encoder_decoder/
https://en.wikipedia.org/wiki/Receiver_operating_characteristic
https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5
https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62
http://jalammar.github.io/illustrated-word2vec/
https://towardsdatascience.com/learn-word2vec-by-implementing-it-in-tensorflow-45641adaf2ac
https://machinelearningmastery.com/develop-word-embeddings-python-gensim/
https://machinelearningmastery.com/deep-learning-for-nlp/
https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/
https://magenta.tensorflow.org/
https://magenta.tensorflow.org/piano-transformer
https://magenta.tensorflow.org/studio
https://www.midi.org/articles-old/google-magenta-making-music-with-midi-and-machine-learning
https://blog.google/technology/ai/behind-magenta-tech-rocked-io/
https://towardsdatascience.com/simple-introduction-to-convolutional-neural-networks-cdf8d3077bac
https://towardsdatascience.com/illustrated-10-cnn-architectures-95d78ace614d
https://www.freecodecamp.org/news/an-intuitive-guide-to-convolutional-neural-networks-260c2de0a050/
https://medium.com/technologymadeeasy/the-best-explanation-of-convolutional-neural-networks-on-the-internet-fbb8b1ad5df8
https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/
https://towardsdatascience.com/illustrated-guide-to-recurrent-neural-networks-79e5eb8049c9
http://kurious.pub/blog/4
https://builtin.com/data-science/recurrent-neural-networks-and-lstm
https://medium.com/@annikabrundyn1/the-beginners-guide-to-recurrent-neural-networks-and-text-generation-44a70c34067f
https://skymind.ai/wiki/lstm



On Mon, Nov 4, 2019 at 7:20 PM Krishna Srinivasan <krishna2@gmail.com> wrote:
https://en.wikipedia.org/wiki/Universal_approximation_theorem
https://heartbeat.fritz.ai/k-means-clustering-using-sklearn-and-python-4a054d67b187
https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html
https://arxiv.org/pdf/1409.0473.pdf
https://arxiv.org/pdf/1902.02181.pdf
https://www.saama.com/blog/attention-mechanism-benefits-and-applications/
https://explosion.ai/blog/deep-learning-formula-nlp
https://ruder.io/deep-learning-nlp-best-practices/index.html#attention
https://towardsdatascience.com/attn-illustrated-attention-5ec4ad276ee3
https://arxiv.org/pdf/1703.03906.pdf

-------------------------
https://www.kalzumeus.com/2019/10/28/tether-and-bitfinex/

-------------------------
https://www.technologyreview.com/s/614666/ai-machine-learning-music-feel-good/amp/
https://towardsdatascience.com/beginning-machine-learning-650add627e79
https://www.sciencealert.com/prime-number-theorems-conjectures-explained/amp
https://www.searchenginejournal.com/bert-generate-meta-descriptions/332585/amp/
https://medium.com/tensorflow/using-tensorflow-2-for-state-of-the-art-natural-language-processing-102445cda54a
http://www.bbc.com/culture/story/20191022-what-are-the-best-first-lines-in-fiction
https://towardsdatascience.com/creating-word-embeddings-for-out-of-vocabulary-oov-words-such-as-singlish-3fe33083d466
https://marketingland.com/welcome-bert-googles-latest-search-algorithm-to-better-understand-natural-language-269910/amp
https://towardsdatascience.com/nlp-extract-contextualized-word-embeddings-from-bert-keras-tf-67ef29f60a7b
https://blog.scaleway.com/2019/understanding-text-with-bert/amp/
https://www.sciencealert.com/mathematicians-have-discovered-an-astonishing-new-way-to-multiply-large-numbers/amp
https://towardsdatascience.com/visualisation-of-embedding-relations-word2vec-bert-64d695b7f36
https://aiweirdness.com/post/188342947482/halloween-costumes-by-the-neural-net-gpt-2/amp
https://towardsdatascience.com/understanding-bert-is-it-a-game-changer-in-nlp-7cca943cf3ad
https://israelg99.github.io/2017-03-23-Word2Vec-Explained/
https://www.wired.com/story/ai-pioneer-algorithms-understand-why/amp
https://towardsdatascience.com/teaching-a-neural-net-to-play-blackjack-8ec5f39809e2
https://towardsdatascience.com/tensorflow-2-0-create-and-train-a-vanilla-cnn-on-google-colab-c7a0ac86d61b
https://towardsdatascience.com/simple-transformers-introducing-the-easiest-bert-roberta-xlnet-and-xlm-library-58bf8c59b2a3
https://www.apptic.me/blog/how-to-train-a-neural-net-to-play-cards.php
https://towardsdatascience.com/implementing-word2vec-in-pytorch-skip-gram-model-e6bae040d2fb
https://towardsdatascience.com/machine-learning-word-embedding-sentiment-classification-using-keras-b83c28087456
https://appliedmachinelearning.blog/2019/03/04/state-of-the-art-text-classification-using-bert-model-predict-the-happiness-hackerearth-challenge/amp/
https://towardsdatascience.com/deconstructing-bert-reveals-clues-to-its-state-of-art-performance-in-nlp-tasks-76a7e828c0f1
https://classicalpoets.org/2018/05/24/10-favorite-shakespeare-sonnets/
https://towardsdatascience.com/nlp-extract-contextualized-word-embeddings-from-bert-keras-tf-67ef29f60a7b
https://towardsdatascience.com/bert-classifier-just-another-pytorch-model-881b3cf05784
https://towardsdatascience.com/fse-2b1ffa791cf9
https://github.com/tensorflow/text
https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21
https://medium.com/syncedreview/going-beyond-gan-new-deepmind-vae-model-generates-high-fidelity-human-faces-b1cc08fa4bbb
https://github.com/bollu/bollu.github.io#everything-you-know-about-word2vec-is-wrong
https://www.pyimagesearch.com/2018/09/10/keras-tutorial-how-to-get-started-with-keras-deep-learning-and-python/
https://medium.com/datadriveninvestor/deep-learning-with-python-and-fast-ai-part-2-nlp-classification-with-transfer-learning-e7aaf7514e04
https://medium.com/@narjes.karmani/reinforcement-learning-fundamentals-469a91e40fce
https://medium.com/apache-mxnet/gluon-nlp-bert-6a489bdd3340
http://jalammar.github.io/illustrated-transformer/

------------------------
https://www.coursera.org/specializations/tensorflow-in-practice
https://www.coursera.org/specializations/aml
https://www.coursera.org/specializations/machine-learning-reinforcement-finance






On Tue, Oct 22, 2019 at 5:20 AM Krishna Srinivasan <krishna2@gmail.com> wrote:
https://news.ycombinator.com/item?id=21242343
https://www.newyorker.com/magazine/2019/10/14/can-a-machine-learn-to-write-for-the-new-yorker
http://www.oranlooney.com/post/ml-from-scratch-part-6-pca/


On Fri, Oct 18, 2019 at 2:17 PM Krishna Srinivasan <krishna2@gmail.com> wrote:
Math for Machine Learning book:https://mml-book.github.io/book/mml-book.pdf

Deep Learning with PyTorch:https://news.ycombinator.com/item?id=21240057



On Mon, Sep 16, 2019 at 6:11 PM Krishna Srinivasan <krishna2@gmail.com> wrote:
Deep Learning Reading List:https://github.com/ChristosChristofidis/awesome-deep-learning

https://github.com/aikorea/awesome-rl#papers--thesis

http://web.archive.org/web/20170612030342/http://karpathy.github.io/2016/09/07/phd/

https://spinningup.openai.com/en/latest/spinningup/keypapers.html



On Tue, Sep 10, 2019 at 4:59 PM Krishna Srinivasan <krishna2@gmail.com> wrote:
http://nlp.fast.ai/classification/2018/05/15/introducting-ulmfit.html
https://towardsdatascience.com/document-embedding-techniques-fed3e7a6a25d
https://blog.scaleway.com/2019/building-a-machine-reading-comprehension-system-using-the-latest-advances-in-deep-learning-for-nlp/
https://news.ycombinator.com/item?id=15938082
https://ai.google/research/people/author37567/
https://news.ycombinator.com/item?id=20773992
https://blog.usejournal.com/opengpt-2-we-replicated-gpt-2-because-you-can-too-45e34e6d36dc
https://blog.floydhub.com/gpt2/
https://transformer.huggingface.co/
https://blog.dominodatalab.com/deep-reinforcement-learning/
https://towardsdatascience.com/why-do-we-use-embeddings-in-nlp-2f20e1b632d2




On Sun, Aug 25, 2019 at 10:46 AM Krishna Srinivasan <krishna2@gmail.com> wrote:
https://towardsdatascience.com/an-implementation-guide-to-word2vec-using-numpy-and-google-sheets-13445eebd281

https://towardsdatascience.com/step-by-step-tutorial-on-linear-regression-with-stochastic-gradient-descent-1d35b088a843

https://news.ycombinator.com/item?id=20524543

https://victorzhou.com/blog/intro-to-rnns/

https://sites.google.com/view/deep-rl-bootcamp/lectures



On Sun, Aug 25, 2019 at 9:15 AM Krishna Srinivasan <krishna2@gmail.com> wrote:
https://towardsdatascience.com/deep-learning-from-scratch-and-using-tensorflow-in-python-34aad75f939

Lots of ML: https://blog.floydhub.com/

Information theory for intelligent people:http://tuvalu.santafe.edu/~simon/it.pdf
Shannon's entropy:http://math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf
Visual information theory:https://colah.github.io/posts/2015-09-Visual-Information/

Are we making progress:https://arxiv.org/pdf/1907.06902v1.pdf

Statistical modeling : Two cultures:http://www2.math.uu.se/~thulin/mm/breiman.pdf

Singapore's how to build good software:https://www.csc.gov.sg/articles/how-to-build-good-software


On Fri, Aug 23, 2019 at 9:00 AM Krishna Srinivasan <krishna2@gmail.com> wrote:
http://ruder.io/state-of-transfer-learning-in-nlp/

http://www.peterbloem.nl/blog/transformers
https://news.ycombinator.com/item?id=20773992

https://medium.com/@vanya_cohen/opengpt-2-we-replicated-gpt-2-because-you-can-too-45e34e6d36dc
https://news.ycombinator.com/item?id=20771604




On Thu, Aug 15, 2019 at 6:48 PM Krishna Srinivasan <krishna2@gmail.com> wrote:
http://nlp.seas.harvard.edu/2018/04/03/attention.html

On Sun, Jun 23, 2019 at 6:55 PM Krishna Srinivasan <krishna2@gmail.com> wrote:
http://web.stanford.edu/class/cs224u/

On Fri, Jun 21, 2019 at 9:22 PM Krishna Srinivasan <krishna2@gmail.com> wrote:
Current top tabs for learning:
https://course.fast.ai/videos/?lesson=1http://course18.fast.ai/part2.htmlhttps://www.fast.ai/2018/04/29/categorical-embeddings/https://hackernoon.com/interview-with-deep-learning-researcher-and-leader-of-openmined-andrew-trask-77cd33570a8chttps://www.fast.ai/2018/07/12/auto-ml-1/
https://www.fast.ai/2018/07/16/auto-ml2/
https://www.fast.ai/2018/07/23/auto-ml-3/
http://nlp.fast.ai/

https://www.coursera.org/specializations/tensorflow-in-practice

https://towardsdatascience.com/animated-rnn-lstm-and-gru-ef124d06cf45
https://towardsdatascience.com/attn-illustrated-attention-5ec4ad276ee3
https://towardsdatascience.com/illustrated-efficient-neural-architecture-search-5f7387f9fb6

https://towardsdatascience.com/step-by-step-tutorial-on-linear-regression-with-stochastic-gradient-descent-1d35b088a843
https://towardsdatascience.com/an-implementation-guide-to-word2vec-using-numpy-and-google-sheets-13445eebd281



On Fri, Apr 5, 2019 at 6:56 PM Krishna Srinivasan <krishna2@gmail.com> wrote:
Nice article on word2vec and has a bunch of awesome links:https://jalammar.github.io/illustrated-word2vec/
https://www.preview.nearist.ai/paid-ebook-and-tutorial
http://ruder.io/word-embeddings-1/index.html
http://ruder.io/word-embeddings-softmax/
https://web.stanford.edu/~jurafsky/slp3/

This is the main article's (first link) hn post with good comments and more links:https://news.ycombinator.com/item?id=19498356

https://jalammar.github.io/illustrated-bert/



On Thu, Apr 4, 2019 at 10:59 AM Krishna Srinivasan <krishna2@gmail.com> wrote:
Couple of course links from Stanford NLP + DL :http://web.stanford.edu/class/cs224n/
https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1184/syllabus.html
The first one is new but uses pytorch. The second one is bit old but uses tensorflow.
https://monkeylearn.com/text-analysis/



On Fri, Mar 8, 2019 at 7:04 PM Krishna Srinivasan <krishna2@gmail.com> wrote:
Writing a Neural Network from scratch in Python:
https://victorzhou.com/blog/intro-to-neural-networks/

On Fri, Mar 8, 2019 at 5:28 PM Krishna Srinivasan <krishna2@gmail.com> wrote:
CMU LTI NLP course:http://phontron.com/class/nn4nlp2019/schedule.html

On Tue, Mar 5, 2019 at 12:07 PM Krishna Srinivasan <krishna2@gmail.com> wrote:
Very good book on Theoretical COmputer Science:https://introtcs.org/public/lec_13_Cook_Levin.html

The chapter on p, np, ..etc is good - I should use this as model for simplified explanation for savit.


On Fri, Feb 15, 2019 at 6:36 PM Krishna Srinivasan <krishna2@gmail.com> wrote:
A free book on Reinforcement Learning:
https://arxiv.org/pdf/1811.12560.pdf

GANs :https://medium.com/@jonathan_hui/gan-whats-generative-adversarial-networks-and-its-application-f39ed278ef09
https://medium.com/@jonathan_hui/gan-some-cool-applications-of-gans-4c9ecca35900

https://ai.googleblog.com/2018/08/introducing-new-framework-for-flexible.html

https://blog.openai.com/better-language-models/#
https://news.ycombinator.com/item?id=19163522



On Thu, Jan 31, 2019 at 4:01 PM Krishna Srinivasan <krishna2@gmail.com> wrote:
Some long pending C++ links:https://boredzo.org/pointers/http://www.c-faq.com/aryptr/index.htmlhttp://www.dietmar-kuehl.de/mirror/c++-faq/references.htmlhttps://isocpp.org/faq

On Sun, Jan 27, 2019 at 12:53 AM Krishna Srinivasan <krishna2@gmail.com> wrote:
Looks like fast.ai is the best way to go about this. They have a new V3 of their course completely redone.https://news.ycombinator.com/item?id=19000027
https://www.fast.ai/2019/01/24/course-v3/
https://course.fast.ai/
http://course18.fast.ai/part2.html
https://explained.ai/matrix-calculus/index.html
https://blog.openai.com/spinning-up-in-deep-rl/

https://towardsdatascience.com/everything-you-need-to-know-about-neural-networks-and-backpropagation-machine-learning-made-easy-e5285bc2be3a

https://austingwalters.com/neural-networks-to-production-from-an-engineer/
https://austingwalters.com/word-embedding-and-data-splitting/

https://bair.berkeley.edu/blog/2017/09/12/learning-to-optimize-with-rl/

https://www.kdnuggets.com/2019/01/burkov-self-supervised-learning-word-embeddings.html

And a slightly off-topic post by Sam Altman : How to be Successful:http://blog.samaltman.com/how-to-be-successful

And a bit in to the C++ land:https://quuxplusone.github.io/blog/2019/01/20/covariance-and-contravariance/
https://github.com/ssloy/tinyraytracer/wiki


On Sat, Jan 12, 2019 at 8:13 AM Krishna Srinivasan <krishna2@gmail.com> wrote:
Few more good links to read:https://towardsdatascience.com/neural-networks-and-philosophy-of-language-31c34c0796da
https://allennlp.org/elmo
https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html
https://en.wikipedia.org/wiki/Distributional_semantics
https://aurelieherbelot.net/research/distributional-semantics-intro/


Some interesting articles on language / nlp:http://nautil.us/issue/54/the-unspoken/the-rise-and-fall-of-the-english-sentence


On Sun, Jan 6, 2019 at 3:18 PM Krishna Srinivasan <krishna2@gmail.com> wrote:
UC Berkeley's Deep Learning course with sections on CNN / RNN / NLP and Word Embeddings:http://d2l.ai/chapter_natural-language-processing/index.html


On Sat, Jan 5, 2019 at 7:22 PM Krishna Srinivasan <krishna2@gmail.com> wrote:
ML / NLP related articles and readings:https://mlwhiz.com/blog/2017/04/09/word_vec_embeddings_examples_understanding/
https://mlwhiz.com/blog/2018/12/17/text_classification/
https://mlwhiz.com/blog/2017/02/05/Machine_learning_algorithms_for_data_scientist/
https://mlwhiz.com/blog/2015/08/19/MCMC_Algorithms_Beta_Distribution/
https://mlwhiz.com/blog/2015/08/21/MCMC_Algorithms_Cryptography/

https://jeffhuang.com/best_paper_awards.html
https://jalammar.github.io/illustrated-bert/
https://thegradient.pub/nlp-imagenet/

https://hackernoon.com/generating-lyrics-using-deep-multi-layer-lstm-b28ee8124936
https://towardsdatascience.com/ai-generates-taylor-swifts-song-lyrics-6fd92a03ef7e
http://warmspringwinds.github.io/pytorch/rnns/2018/01/27/learning-to-generate-lyrics-and-music-with-recurrent-neural-networks/


On Thu, Dec 27, 2018 at 6:01 PM Krishna Srinivasan <krishna2@gmail.com> wrote:
https://www.coursera.org/learn/language-processing/home/welcome
